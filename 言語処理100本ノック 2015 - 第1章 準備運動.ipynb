{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック 2015\n",
    "\n",
    "http://www.cl.ecei.tohoku.ac.jp/nlp100/\n",
    "\n",
    "言語処理100本ノックは，実践的な課題に取り組みながら，プログラミング，データ分析，研究のスキルを楽しく習得することを目指した問題集です\n",
    "\n",
    "* 実用的でワクワクするような題材を厳選しました\n",
    "* 言語処理に加えて，統計や機械学習などの周辺分野にも親しめます\n",
    "* 研究やデータ分析の進め方，作法，スキルを修得できます\n",
    "* 問題を解くのに必要なデータ・コーパスを配布しています\n",
    "* 言語はPythonを想定していますが，他の言語にも対応しています\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 第1章: 準備運動\n",
    "\n",
    "テキストや文字列を扱う題材に取り組みながら，プログラミング言語のやや高度なトピックを復習します．\n",
    "\n",
    "> 文字列, ユニコード, リスト型, 辞書型, 集合型, イテレータ, スライス, 乱数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    "\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"stressed\"[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 「パタトクカシーー」\n",
    "\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"パタトクカシーー\"[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=\"\"\n",
    "for a, b in zip(\"パトカー\",\"タクシー\"):\n",
    "    out += a + b\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([a + b for a, b in zip(\"パトカー\", \"タクシー\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 円周率\n",
    "\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "[len(word.replace(',','').replace('.','')) for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. 元素記号\n",
    "\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Al': 13,\n",
       " 'Ar': 18,\n",
       " 'B': 5,\n",
       " 'Be': 4,\n",
       " 'C': 6,\n",
       " 'Ca': 20,\n",
       " 'Cl': 17,\n",
       " 'F': 9,\n",
       " 'H': 1,\n",
       " 'He': 2,\n",
       " 'K': 19,\n",
       " 'Li': 3,\n",
       " 'Mi': 12,\n",
       " 'N': 7,\n",
       " 'Na': 11,\n",
       " 'Ne': 10,\n",
       " 'O': 8,\n",
       " 'P': 15,\n",
       " 'S': 16,\n",
       " 'Si': 14}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "{(word[:1] if i in [j-1 for j in [1, 5, 6, 7, 8, 9, 15, 16, 19]] else word[:2]):i+1 \n",
    " for i,word in enumerate(sentence.split())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. n-gram\n",
    "\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 1-gram: [['I'], ['am'], ['an'], ['NLPer']]\n",
      "word 2-gram: [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "word 3-gram: [['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n",
      "word 4-gram: [['I', 'am', 'an', 'NLPer']]\n",
      "char 1-gram: ['I', 'a', 'm', 'a', 'n', 'N', 'L', 'P', 'e', 'r']\n",
      "char 2-gram: ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n",
      "char 3-gram: ['Iam', 'ama', 'man', 'anN', 'nNL', 'NLP', 'LPe', 'Per']\n",
      "char 4-gram: ['Iama', 'aman', 'manN', 'anNL', 'nNLP', 'NLPe', 'LPer']\n",
      "char 5-gram: ['Iaman', 'amanN', 'manNL', 'anNLP', 'nNLPe', 'NLPer']\n",
      "char 6-gram: ['IamanN', 'amanNL', 'manNLP', 'anNLPe', 'nNLPer']\n",
      "char 7-gram: ['IamanNL', 'amanNLP', 'manNLPe', 'anNLPer']\n",
      "char 8-gram: ['IamanNLP', 'amanNLPe', 'manNLPer']\n",
      "char 9-gram: ['IamanNLPe', 'amanNLPer']\n",
      "char 10-gram: ['IamanNLPer']\n"
     ]
    }
   ],
   "source": [
    "def ngram(sequence, n):\n",
    "    return [sequence[i:i+n] for i in range(len(sequence)-n+1) ]\n",
    "    out = []\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        out.append(sequence[i : i + n])\n",
    "    return out\n",
    "\n",
    "sequence = \"I am an NLPer\"\n",
    "for n in range(1,5):\n",
    "    print(\"word {0}-gram: {1}\".format(n, ngram(sequence.split(),n)))\n",
    "\n",
    "for n in range(1,11):\n",
    "    print(\"char {0}-gram: {1}\".format(n, ngram(sequence.replace(' ',''), n)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. 集合\n",
    "\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X: {'ra', 'is', 'di', 'ar', 'pa', 'ad', 'se', 'ap'}\n",
      "           Y: {'ra', 'ag', 'gr', 'ar', 'ph', 'pa', 'ap'}\n",
      "       union: {'ra', 'is', 'ag', 'gr', 'di', 'ar', 'ph', 'pa', 'ad', 'se', 'ap'}\n",
      "intersection: {'ra', 'ap', 'pa', 'ar'}\n",
      "  difference: {'se', 'is', 'di', 'ad'}\n"
     ]
    }
   ],
   "source": [
    "def ngram(sequence, n):\n",
    "    return [sequence[i:i+n] for i in range(len(sequence)-n+1) ]\n",
    "    out = []\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        out.append(sequence[i : i + n])\n",
    "    return out\n",
    "\n",
    "sequence1 = \"paraparaparadise\"\n",
    "X = set(ngram(sequence1, 2))\n",
    "\n",
    "sequence2 = \"paragraph\"\n",
    "Y = set(ngram(sequence2, 2))\n",
    "\n",
    "print(\"           X: {0}\".format(X))\n",
    "print(\"           Y: {0}\".format(Y))\n",
    "print(\"       union: {0}\".format(X.union(Y)))\n",
    "print(\"intersection: {0}\".format(X.intersection(Y)))\n",
    "print(\"  difference: {0}\".format(X.difference(Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. テンプレートによる文生成\n",
    "\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def message(x, y, z):\n",
    "    return \"{0}時の{1}は{2}\".format(x, y, z)\n",
    "\n",
    "message(x=12, y=\"気温\", z=22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08. 暗号文\n",
    "\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message:\n",
      "I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\n",
      "\n",
      "Encrypted message:\n",
      "I xlfowm'g yvorvev gszg I xlfow zxgfzoob fmwvihgzmw dszg I dzh ivzwrmt : gsv ksvmlnvmzo kldvi lu gsv sfnzm nrmw .\n",
      "\n",
      "Decrypted message:\n",
      "I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\n"
     ]
    }
   ],
   "source": [
    "def cipher(message):\n",
    "    return \"\".join([chr(219 - ord(char)) if ('a' <= char <='z') else char for char in message])\n",
    "\n",
    "message = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(\"Original message:\")\n",
    "print(message)\n",
    "\n",
    "encrypted = cipher(message)\n",
    "print(\"\\nEncrypted message:\")\n",
    "print(encrypted)\n",
    "\n",
    "decrypted = cipher(encrypted)\n",
    "print(\"\\nDecrypted message:\")\n",
    "print(decrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09. Typoglycemia\n",
    "\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I cl'udont bveleie that I could atcaully unadstenrd what I was rnaiedg : the pennoeahml power of the hmuan mind .\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sentence = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "\" \".join([(word[0] + \"\".join(random.sample(word[1:-1], len(word[1:-1]))) + word[-1]) if 4 < len(word) else word\n",
    "          for word in sentence.split()])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [yamaconda]",
   "language": "python",
   "name": "Python [yamaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
